# 神经网络

## 神经元模型

**神经网络的定义**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281610523.png" style="zoom:80%;" />

**M-P神经元模型**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281613704.png" style="zoom:67%;" />

**典型的激活函数**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281614001.png" style="zoom:80%;" />

> **理想激活函数是阶跃函数**, 0表示抑制神经元而1表示激活神经元
> 阶跃函数具有**不连续、不光滑**等不好的性质, **常用的是 Sigmoid 函数**

## 感知机与多层网络

**感知机**

> 感知机由两层神经元组成, 输入层接受外界输入信号传递给输出层, 输出层是M-P神经元（激活函数为阶跃函数时亦称阈值逻辑单元）
> 感知机能够容易地**实现逻辑与、或、非运算**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281618264.png" style="zoom:80%;" />

**感知机学习**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281622279.png" style="zoom:80%;" />

**感知机求解与、或、非问题**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281624940.png" style="zoom:80%;" />

> ###### 若两类模式线性可分, 则感知机的学习过程一定会收敛；否则感知机的学习过程将会发生震荡
>
> 单层感知机的学习能力非常有限, 只能解决线性可分问题

**多层感知机**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281626296.png" style="zoom:80%;" />

> 输出层与输入层之间的一层神经元, 被称之为**隐层或隐含层**, 隐含层和输 出层神经元都是具有激活函数的功能神经元

**多层前馈网络**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281628929.png" style="zoom:80%;" />

## 误差逆传播算法

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281630530.png" style="zoom:80%;" /><img src="https://gitee.com/cpicture/picture-1/raw/master/202110281632004.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281639390.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281640771.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281642773.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281643840.png" style="zoom:80%;" />

> **伪代码描述**

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281645040.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281647167.png" style="zoom:80%;" />

**多层前馈网络表示能力**

> 只需要一个包含足够多神经元的隐层, 多层前馈神经网络就能以任意精度逼近任 意复杂度的连续函数
> [Hornik et al. ,  1989]

**多层前馈网络局限**

> 如何设置**隐层神经元的个数**仍然是个**未决问题**. 实际应用中通常使**用“试错 法”调整**
> 神经网络由于强大的表示能力, **经常遭遇过拟合**. 表现为：训练误差持续降低, 但测试误差却可能上升

**缓解过拟合的策略**

> **早停**：在训练过程中, 若训练误差降低, 但验证误差升高, 则停止训练
> **正则化**：在误差目标函数中增加一项描述网络复杂程度的部分, 例如连接权 值与阈值的平方和

## 全局最小与局部最小

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281651176.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281652261.png" style="zoom:80%;" />

## 深度学习

**深度学习模型**

> 典型的深度学习模型就是很**深层的神经网络**. 

**模型复杂度**

> 增加隐层**神经元的数目 (模型宽度)**
> 增加**隐层数目（模型深度）**
> 从增加模型复杂度的角度看, **增加隐层的数目比增加隐层神经元的数目更有效. 这是因为增加隐层数不仅增加了拥有激活函数的神经元数目, 还增加了激活函数嵌套的层数.**

**复杂模型难点**

> 多隐层网络难以直接用经典算法（例如标准BP算法）进行训练, 因为误差在 多隐层内逆传播时, 往往会”发散”而不能收敛到稳定状态.

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281656252.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281657087.png" style="zoom:80%;" />

<img src="https://gitee.com/cpicture/picture-1/raw/master/202110281657447.png" style="zoom:80%;" />
